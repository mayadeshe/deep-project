{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# Vanilla DDPM Inpainting — Quantitative Evaluation\n\nThis notebook evaluates the vanilla DDPM inpainting pipeline (`vanilla_inpaint.py`) on **N images**\nfrom the **MS COCO val2017** dataset, using **MNIST digit silhouettes** as masks.\n\nThe digit silhouette (~10% of the image) is erased and reconstructed.\n\n**Pipeline:** For each image we use the COCO caption as the prompt and measure reconstruction quality\n(SSIM, PSNR, LPIPS) on the **inpainted region only**.\n\n**Output layout:**\n```\neval_results/\n  originals/           ← shared originals (written once)\n  inpainted/           ← inpainting outputs\n  masks/               ← masks (.pt)\n  checkpoint.json\n  metric_distributions.png\n  top10_best.png\n  top10_worst.png\n```"
  },
  {
   "cell_type": "code",
   "id": "cell-1-imports",
   "metadata": {},
   "source": [
    "import sys, os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim_fn\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import lpips\n",
    "\n",
    "# ---- Config ----\n",
    "N_IMAGES       = 1000\n",
    "IMAGE_SIZE     = (512, 512)\n",
    "SEED           = 42\n",
    "STEPS          = 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "DATA_ROOT      = \"./data\"\n",
    "RESULTS_DIR    = \"./eval_results\"\n",
    "\n",
    "CHECKPOINT = os.path.join(RESULTS_DIR, \"checkpoint.json\")\n",
    "\n",
    "COCO_ROOT      = os.path.join(DATA_ROOT, \"coco\")\n",
    "COCO_IMG_DIR   = os.path.join(COCO_ROOT, \"val2017\")\n",
    "COCO_ANN_FILE  = os.path.join(COCO_ROOT, \"annotations\", \"captions_val2017.json\")\n",
    "COCO_INST_FILE = os.path.join(COCO_ROOT, \"annotations\", \"instances_val2017.json\")\n",
    "\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"originals\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"inpainted\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(RESULTS_DIR, \"masks\"),     exist_ok=True)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Config: N_IMAGES={N_IMAGES}, SIZE={IMAGE_SIZE}, STEPS={STEPS}, GUIDANCE={GUIDANCE_SCALE}\")\n",
    "print(f\"Output dirs: {RESULTS_DIR}/{{inpainted,masks}}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-2-datasets",
   "metadata": {},
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "_pbar = None\n",
    "\n",
    "def reporthook(block_num, block_size, total_size):\n",
    "    global _pbar\n",
    "    if _pbar is None:\n",
    "        _pbar = tqdm(total=total_size, unit=\"B\", unit_scale=True, unit_divisor=1024)\n",
    "    downloaded = block_num * block_size\n",
    "    _pbar.n = min(downloaded, total_size)\n",
    "    _pbar.refresh()\n",
    "    if downloaded >= total_size:\n",
    "        _pbar.close()\n",
    "        _pbar = None\n",
    "\n",
    "# ---- Download COCO val2017 images (~1 GB) ----\n",
    "os.makedirs(COCO_ROOT, exist_ok=True)\n",
    "\n",
    "IMG_URL = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "ANN_URL = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "\n",
    "if not os.path.isdir(COCO_IMG_DIR):\n",
    "    img_zip = os.path.join(COCO_ROOT, \"val2017.zip\")\n",
    "    print(\"Downloading COCO val2017 images (~1 GB)...\")\n",
    "    urllib.request.urlretrieve(IMG_URL, img_zip, reporthook)\n",
    "    print(\"Extracting images...\")\n",
    "    with zipfile.ZipFile(img_zip) as z:\n",
    "        z.extractall(COCO_ROOT)\n",
    "    os.remove(img_zip)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(f\"COCO images already present: {COCO_IMG_DIR}\")\n",
    "\n",
    "# ---- Download COCO annotations (~240 MB) ----\n",
    "if not os.path.exists(COCO_ANN_FILE):\n",
    "    ann_zip = os.path.join(COCO_ROOT, \"annotations_trainval2017.zip\")\n",
    "    print(\"Downloading COCO annotations (~240 MB)...\")\n",
    "    urllib.request.urlretrieve(ANN_URL, ann_zip, reporthook)\n",
    "    print(\"Extracting annotations...\")\n",
    "    with zipfile.ZipFile(ann_zip) as z:\n",
    "        z.extractall(COCO_ROOT)\n",
    "    os.remove(ann_zip)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(f\"COCO annotations already present: {COCO_ANN_FILE}\")\n",
    "\n",
    "# ---- Load captions JSON → build img_id -> [captions] mapping ----\n",
    "with open(COCO_ANN_FILE, \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "coco_id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in coco_data[\"images\"]}\n",
    "\n",
    "coco_captions = {}\n",
    "for ann in coco_data[\"annotations\"]:\n",
    "    img_id = ann[\"image_id\"]\n",
    "    coco_captions.setdefault(img_id, []).append(ann[\"caption\"])\n",
    "\n",
    "# Exclude categories inpainting is very noisy in.\n",
    "EXCLUDED_SUPERCATEGORIES = {\"person\", \"animal\", \"sports\", \"food\"}\n",
    "\n",
    "with open(COCO_INST_FILE, \"r\") as f:\n",
    "    inst_data = json.load(f)\n",
    "\n",
    "excluded_cat_ids = {\n",
    "    c[\"id\"] for c in inst_data[\"categories\"]\n",
    "    if c[\"supercategory\"] in EXCLUDED_SUPERCATEGORIES\n",
    "}\n",
    "excluded_image_ids = {\n",
    "    a[\"image_id\"] for a in inst_data[\"annotations\"]\n",
    "    if a[\"category_id\"] in excluded_cat_ids\n",
    "}\n",
    "print(f\"Images excluded (person/animal/sports/food): \"\n",
    "      f\"{len(excluded_image_ids)} / {len(coco_id_to_filename)}\")\n",
    "\n",
    "# ---- Keep only scene/room/nature/vehicle images that have a caption and exist on disk ----\n",
    "valid_ids = [\n",
    "    img_id for img_id, caps in coco_captions.items()\n",
    "    if img_id not in excluded_image_ids\n",
    "    and os.path.exists(os.path.join(COCO_IMG_DIR, coco_id_to_filename[img_id]))\n",
    "]\n",
    "print(f\"Scene/room/nature/vehicle images remaining: {len(valid_ids)}\")\n",
    "\n",
    "# ---- Sample N_IMAGES image IDs deterministically ----\n",
    "rng = np.random.RandomState(SEED)\n",
    "sampled_ids = rng.choice(valid_ids, size=N_IMAGES, replace=False).tolist()\n",
    "\n",
    "# Build ordered list of (filename, first_caption) for the sampled images\n",
    "coco_samples = [\n",
    "    (coco_id_to_filename[img_id], coco_captions[img_id][0])\n",
    "    for img_id in sampled_ids\n",
    "]\n",
    "\n",
    "# ---- Load MNIST (test set) ----\n",
    "mnist = torchvision.datasets.MNIST(\n",
    "    root=DATA_ROOT, train=False, download=True\n",
    ")\n",
    "\n",
    "# ---- Sample MNIST indices deterministically ----\n",
    "mnist_indices = rng.choice(len(mnist), size=N_IMAGES, replace=False)\n",
    "\n",
    "print(f\"MNIST dataset size:  {len(mnist)}\")\n",
    "print(f\"Sampled {N_IMAGES} scene/room/nature/vehicle image-mask pairs.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-3-mask-prep",
   "metadata": {},
   "source": "def prepare_mnist_mask(mnist_image, size=IMAGE_SIZE):\n    \"\"\"\n    Inpainting mask: digit silhouette is the erased region (~10% of image).\n    Convention: 1 = keep, 0 = inpaint.\n    Digit pixels (bright >127) -> 0 (inpaint), background -> 1 (keep).\n\n    Returns: torch.Tensor of shape (1, 1, H, W)\n    \"\"\"\n    mask_pil = mnist_image.resize(size, Image.NEAREST)\n    mask_np = np.array(mask_pil)\n    # Digit pixels are bright; invert so digit -> 0 (inpaint)\n    mask_binary = (mask_np <= 127).astype(np.float32)\n    mask_tensor = torch.from_numpy(mask_binary).unsqueeze(0).unsqueeze(0)\n    return mask_tensor\n\n\ndef prepare_coco_image(path, size=IMAGE_SIZE):\n    \"\"\"Load a COCO image from disk and resize to the target size.\"\"\"\n    return Image.open(path).convert(\"RGB\").resize(size, Image.LANCZOS)\n\n\ndef apply_mask_for_display(image, mask_tensor):\n    \"\"\"Black out the inpainted region for visualization.\"\"\"\n    img_np = np.array(image).copy()\n    mask_np = mask_tensor.squeeze().numpy()  # (H, W), 1=keep, 0=inpaint\n    img_np[mask_np == 0] = 0  # black for inpainted region\n    return Image.fromarray(img_np)\n\nsample_filename, sample_caption = coco_samples[0]\nsample_img   = prepare_coco_image(os.path.join(COCO_IMG_DIR, sample_filename))\nsample_digit = mnist[mnist_indices[0]][0]\n\nsample_mask   = prepare_mnist_mask(sample_digit)\nsample_masked = apply_mask_for_display(sample_img, sample_mask)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\naxes[0].imshow(sample_img);                           axes[0].set_title(\"Original (COCO)\")\naxes[1].imshow(sample_mask.squeeze(), cmap=\"gray\");   axes[1].set_title(\"Mask (1=keep, 0=inpaint)\")\naxes[2].imshow(sample_masked);                        axes[2].set_title(\"Masked\")\n\nfor ax in axes:\n    ax.axis(\"off\")\n\nplt.suptitle(f'Caption: \"{sample_caption}\"', fontsize=10, y=1.01)\nplt.tight_layout()\nplt.show()\n\nfrac = (sample_mask == 0).float().mean().item() * 100\nprint(f\"Inpainted region: {frac:.1f}% of image\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-4-model",
   "metadata": {},
   "source": [
    "# ---- Import model and inpainting function from vanilla_inpaint.py ----\n",
    "sys.path.insert(0, os.path.abspath(\".\"))\n",
    "from vanilla_inpaint import ddpm_inpaint\n",
    "from cliutils import load_sd_pipeline\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "pipe = load_sd_pipeline(device)\n",
    "pipe.set_progress_bar_config(disable=True)  # suppress inner per-step bar\n",
    "print(\"Model loaded.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-5-inpaint-loop",
   "metadata": {},
   "source": [
    "# ---- Inpainting loop (erase digit silhouette ~10% of image) ----\n",
    "# Saves to: eval_results/originals/, eval_results/inpainted/, eval_results/masks/\n",
    "\n",
    "INPAINTED_DIR = os.path.join(RESULTS_DIR, \"inpainted\")\n",
    "MASKS_DIR     = os.path.join(RESULTS_DIR, \"masks\")\n",
    "ORIGINALS_DIR = os.path.join(RESULTS_DIR, \"originals\")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "start_idx = 0\n",
    "if os.path.exists(CHECKPOINT):\n",
    "    with open(CHECKPOINT, \"r\") as f:\n",
    "        checkpoint = json.load(f)\n",
    "    start_idx = checkpoint.get(\"completed\", 0)\n",
    "    print(f\"Resuming from image {start_idx}/{N_IMAGES}\")\n",
    "\n",
    "for i in tqdm(range(start_idx, N_IMAGES), initial=start_idx,\n",
    "              total=N_IMAGES, desc=\"Inpainting\"):\n",
    "    filename, prompt = coco_samples[i]\n",
    "    img_pil = prepare_coco_image(os.path.join(COCO_IMG_DIR, filename))\n",
    "    mask_tensor = prepare_mnist_mask(mnist[mnist_indices[i]][0])\n",
    "    random_seed = random.randint(1, 100)\n",
    "\n",
    "    inpainted_pil = ddpm_inpaint(\n",
    "        pipe=pipe,\n",
    "        image=img_pil,\n",
    "        mask=mask_tensor,\n",
    "        prompt=prompt,\n",
    "        steps=STEPS,\n",
    "        guidance_scale=GUIDANCE_SCALE,\n",
    "        seed=SEED + random_seed,\n",
    "    )\n",
    "\n",
    "    # Save originals once\n",
    "    orig_path = os.path.join(ORIGINALS_DIR, f\"{i:04d}.png\")\n",
    "    if not os.path.exists(orig_path):\n",
    "        img_pil.save(orig_path)\n",
    "        with open(os.path.join(ORIGINALS_DIR, f\"{i:04d}.json\"), \"w\") as f:\n",
    "            json.dump({\"caption\": prompt}, f)\n",
    "\n",
    "    inpainted_pil.save(os.path.join(INPAINTED_DIR, f\"{i:04d}.png\"))\n",
    "    torch.save(mask_tensor, os.path.join(MASKS_DIR, f\"{i:04d}.pt\"))\n",
    "\n",
    "    with open(CHECKPOINT, \"w\") as f:\n",
    "        json.dump({\"completed\": i + 1, \"last_prompt\": prompt}, f)\n",
    "\n",
    "print(f\"Done. Inpainted {N_IMAGES} images.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-6-metrics",
   "metadata": {},
   "source": "# ---- Metric helpers ----\n\nlpips_model = lpips.LPIPS(net=\"alex\").to(device)\nlpips_model.eval()\n\n\ndef compute_masked_metrics(\n    original,\n    inpainted,\n    mask_tensor,\n):\n    \"\"\"\n    Compute SSIM, PSNR, LPIPS only on the inpainted region.\n    mask_tensor: (1,1,H,W), 1=keep, 0=inpaint.\n    \"\"\"\n    orig_np = np.array(original).astype(np.float64)\n    inp_np  = np.array(inpainted).astype(np.float64)\n    mask_np = mask_tensor.squeeze().numpy()\n    inpaint_mask = (mask_np == 0)\n\n    if not inpaint_mask.any():\n        return {\"ssim\": 1.0, \"psnr\": float(\"inf\"), \"lpips\": 0.0}\n\n    # ---- Bounding box of inpainted region ----\n    rows = np.any(inpaint_mask, axis=1)\n    cols = np.any(inpaint_mask, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    crop_orig = orig_np[rmin:rmax + 1, cmin:cmax + 1]\n    crop_inp  = inp_np[rmin:rmax + 1, cmin:cmax + 1]\n\n    # ---- PSNR: only on inpainted pixels ----\n    masked_orig = orig_np[inpaint_mask]\n    masked_inp  = inp_np[inpaint_mask]\n    mse = np.mean((masked_orig - masked_inp) ** 2)\n    psnr_val = 10.0 * np.log10(255.0 ** 2 / mse) if mse > 0 else float(\"inf\")\n\n    # ---- SSIM: on bounding-box crop ----\n    min_dim = min(crop_orig.shape[0], crop_orig.shape[1])\n    win_size = min(7, min_dim if min_dim % 2 == 1 else min_dim - 1)\n    win_size = max(win_size, 3)\n\n    ssim_val = ssim_fn(\n        crop_orig, crop_inp,\n        data_range=255.0, channel_axis=2, win_size=win_size\n    )\n\n    # ---- LPIPS: on bounding-box crop (avoids black-region artifacts) ----\n    crop_orig_f = crop_orig.astype(np.float32)\n    crop_inp_f  = crop_inp.astype(np.float32)\n\n    orig_t = torch.from_numpy(crop_orig_f).permute(2, 0, 1).unsqueeze(0) / 127.5 - 1.0\n    inp_t  = torch.from_numpy(crop_inp_f).permute(2, 0, 1).unsqueeze(0) / 127.5 - 1.0\n\n    with torch.no_grad():\n        lpips_val = lpips_model(orig_t.to(device), inp_t.to(device)).item()\n\n    return {\"ssim\": ssim_val, \"psnr\": psnr_val, \"lpips\": lpips_val}\n\n\ndef run_metrics(inpainted_dir, masks_dir, originals_dir):\n    \"\"\"\n    Load inpainted images, masks, and originals from disk and compute per-image metrics.\n    Returns a list of result dicts with keys: idx, original, inpainted, mask, caption, ssim, psnr, lpips.\n    \"\"\"\n    results = []\n    for i in tqdm(range(N_IMAGES), desc=f\"Metrics [{os.path.basename(inpainted_dir)}]\"):\n        orig_path    = os.path.join(originals_dir,  f\"{i:04d}.png\")\n        inp_path     = os.path.join(inpainted_dir,  f\"{i:04d}.png\")\n        mask_path    = os.path.join(masks_dir,       f\"{i:04d}.pt\")\n        caption_path = os.path.join(originals_dir,  f\"{i:04d}.json\")\n\n        if not all(os.path.exists(p) for p in [orig_path, inp_path, mask_path]):\n            print(f\"Stopping at image {i} (files not found). Run the inpainting loop first.\")\n            break\n\n        orig_img = Image.open(orig_path)\n        inp_img  = Image.open(inp_path)\n        mask_t   = torch.load(mask_path, weights_only=True)\n\n        caption = \"\"\n        if os.path.exists(caption_path):\n            with open(caption_path) as f:\n                caption = json.load(f).get(\"caption\", \"\")\n\n        metrics = compute_masked_metrics(orig_img, inp_img, mask_t)\n        results.append({\n            \"idx\": i, \"original\": orig_img, \"inpainted\": inp_img,\n            \"mask\": mask_t, \"caption\": caption, **metrics\n        })\n\n    return results\n\n\n# ---- Compute metrics ----\noriginals_dir = os.path.join(RESULTS_DIR, \"originals\")\n\nresults = run_metrics(\n    inpainted_dir=os.path.join(RESULTS_DIR, \"inpainted\"),\n    masks_dir=os.path.join(RESULTS_DIR, \"masks\"),\n    originals_dir=originals_dir,\n)\n\nprint(f\"Metrics computed for {len(results)} images.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-7-summary",
   "metadata": {},
   "source": "# ---- Aggregate statistics ----\nfrom scipy.stats import gaussian_kde\n\ndef print_stats_table(results, label):\n    ssim_v  = np.array([r[\"ssim\"]  for r in results])\n    psnr_v  = np.array([r[\"psnr\"]  for r in results])\n    lpips_v = np.array([r[\"lpips\"] for r in results])\n    print(f\"\\n{'=' * 55}\")\n    print(f\"  {label} — {len(results)} images (inpainted region only)\")\n    print(f\"{'=' * 55}\")\n    print(f\"{'Metric':<10} {'Mean':>10} {'Median':>10} {'Std':>10}\")\n    print(f\"{'-' * 55}\")\n    print(f\"{'SSIM':<10} {ssim_v.mean():>10.4f} {np.median(ssim_v):>10.4f} {ssim_v.std():>10.4f}\")\n    print(f\"{'PSNR':<10} {psnr_v.mean():>10.2f} {np.median(psnr_v):>10.2f} {psnr_v.std():>10.2f}\")\n    print(f\"{'LPIPS':<10} {lpips_v.mean():>10.4f} {np.median(lpips_v):>10.4f} {lpips_v.std():>10.4f}\")\n    print(f\"{'=' * 55}\")\n    return ssim_v, psnr_v, lpips_v\n\nssim_v, psnr_v, lpips_v = print_stats_table(results, \"Inpainting (erase digit ~10%)\")\n\n# ---- KDE distribution plots ----\nfig, axes = plt.subplots(1, 3, figsize=(18, 4))\n\nfor ax, vals, xlabel, title in [\n    (axes[0], ssim_v,  \"SSIM\",                \"SSIM Distribution\"),\n    (axes[1], psnr_v,  \"PSNR (dB)\",           \"PSNR Distribution\"),\n    (axes[2], lpips_v, \"LPIPS (lower=better)\", \"LPIPS Distribution\"),\n]:\n    kde = gaussian_kde(vals, bw_method=\"scott\")\n    x = np.linspace(vals.min() - 0.05 * np.ptp(vals), vals.max() + 0.05 * np.ptp(vals), 500)\n    y = kde(x)\n    ax.plot(x, y, color=\"steelblue\", linewidth=2, label=f\"mean={vals.mean():.3f}\")\n    ax.fill_between(x, y, alpha=0.20, color=\"steelblue\")\n    ax.axvline(vals.mean(), color=\"steelblue\", linestyle=\"--\", linewidth=1.2)\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(\"Density\")\n    ax.legend(fontsize=8)\n\nplt.suptitle(\"Vanilla DDPM Inpainting — Metric Distributions\", fontsize=13, y=1.02)\nplt.tight_layout()\nplt.savefig(os.path.join(RESULTS_DIR, \"metric_distributions.png\"), dpi=150, bbox_inches=\"tight\")\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-8-top10-best",
   "metadata": {},
   "source": "# ---- Visualization helper ----\n\ndef show_top10(results, sort_key=\"ssim\", descending=True, title_prefix=\"\", save_path=None):\n    \"\"\"Display and optionally save a 10-row grid: Original | Masked | Inpainted.\"\"\"\n    sorted_r = sorted(results, key=lambda r: r[sort_key], reverse=descending)\n    top10 = sorted_r[:10]\n\n    direction = \"highest\" if descending else \"lowest\"\n    fig, axes = plt.subplots(10, 3, figsize=(15, 50))\n    fig.suptitle(f\"{title_prefix} (Top 10 — {direction} {sort_key.upper()})\", fontsize=16, y=1.0)\n\n    for row, r in enumerate(top10):\n        masked_vis = apply_mask_for_display(r[\"original\"], r[\"mask\"])\n\n        axes[row, 0].imshow(r[\"original\"])\n        axes[row, 0].set_title(\"Original\" if row == 0 else \"\")\n        axes[row, 0].set_ylabel(\n            f\"#{r['idx']}\\nSSIM={r['ssim']:.3f}\\nPSNR={r['psnr']:.1f}\\nLPIPS={r['lpips']:.3f}\",\n            fontsize=9, rotation=0, labelpad=70, va=\"center\",\n        )\n\n        axes[row, 1].imshow(masked_vis)\n        axes[row, 1].set_title(\"Masked\" if row == 0 else \"\")\n        axes[row, 1].set_xlabel(f'\"{r[\"caption\"]}\"', fontsize=8, labelpad=6)\n\n        axes[row, 2].imshow(r[\"inpainted\"])\n        axes[row, 2].set_title(\"Inpainted\" if row == 0 else \"\")\n\n        for col in range(3):\n            axes[row, col].axis(\"off\")\n        axes[row, 1].xaxis.set_visible(True)\n        axes[row, 1].tick_params(bottom=False, labelbottom=True)\n        axes[row, 1].set_xticks([])\n\n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n    plt.show()\n\n\n# ---- Top 10 BEST ----\nshow_top10(\n    results,\n    sort_key=\"ssim\", descending=True,\n    title_prefix=\"Inpainting — Best Results\",\n    save_path=os.path.join(RESULTS_DIR, \"top10_best.png\"),\n)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-9-top10-worst",
   "metadata": {},
   "source": "# ---- Top 10 WORST ----\nshow_top10(\n    results,\n    sort_key=\"ssim\", descending=False,\n    title_prefix=\"Inpainting — Worst Results\",\n    save_path=os.path.join(RESULTS_DIR, \"top10_worst.png\"),\n)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
